### 排序

#### 冒泡排序
 * 冒泡操作
   + 每冒一次即交换一次
 * 冒泡排序包含两个操作原子，**比较**与**交换**
   + 每交换一次，有序度就加1， 交换次数即逆序度
   
 * 第一，冒泡排序是原地排序算法吗？
   + 冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，
   所以它的空间复杂度为 O(1)，是一个原地排序算法。
   
 * 第二，冒泡排序是稳定的排序算法吗？
   + 是稳定，相等时不交换
   
 * 第三，冒泡排序的时间复杂度是多少？
   + 最好情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡操作
   为O(n)
   + 最坏情况下，要排序的数据刚好倒序，我们需要n次冒泡操作
   为O(n^2)
   + 平均复杂度分析
     - 对于n个数据的数组，这n个数据就有n!种排列方式（从n个数中取n个数排，有多少排列数，An^n=n!排行公式）。
     不同排序方式，冒泡排序执行时间不同。所有来分析**有序度**和**逆序度**
     - 有序度：具有有序关系对的个数。a[i] < a[j] 且 i < j
     > 有序度是一个组合问题，即从n个数中取出2个数分组，每个组是有序的
     > 如：2, 4, 3, 1, 5
     >> (2,4), (2,3), (2, 5), (4, 5), (3, 5), (1, 5)
     - 满有序度：是一个完全有序的数组，有序度为n*(n-1)/2
     > 组合公式 Cn^2 = An^2/ A2^2 = n*(n-1)/2!
        ``` 
        一楼给的应该是等差数列前N 项和公式，这里用高中排列组合中的组合公式来解释应该会比较合适。
        要做的事情是求 n 个元素的满序度，换成组合概念就是从 n 个元素中选出 2 个元素的组合。根据公式(这里用逗号区分上下标，逗号前为下标，逗号后为上标)
         Cn,2 = An,2 / A2,2 = An,2 / 2! = n*(n-1)/2
        ```
     - 逆序度 = 满有序度 - 有序度
     我们排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度
       
     - 平均多少呢？
       1. 最坏有序度为0， 所以要进行n(n-1)/2次交换
       2. 最好满有序，不需要交换
       所以我们取个中间值即：n(n-1)/4来表示有序度不高也不低的平均情况
     - 平均情况需要n(n-1)/4次交换，比较操作肯定要比交换操作多，而且复杂度上限是O(n^2)
     ,所以平均情况下的时间复杂度就是O(n^2)
     
#### 插入排序
 * 将数组分为两个区间：**已排序区间** 和 **未排序区间**，
 初始排序区间只有一个元素，
 * 插入算法核心就是取未排序区间元素，在已排序区间中找到合适的插入位置将其插入
 
 * 插入排序也包含两个操作：比较和移动。
   + 当我们需要将一个元素a插入已排序区间时，需要拿a与已排序区间的元素依次比较大小，
   找到合适的插入位置，我们还需要将插入点之后元素顺序往后移动一位，这样才能腾出位置
   给元素a插入
   + 对于不同的查找插入点方法（从头到尾或从尾到头），元素的比较次数是有区别的。
   但对于一个给定初始序列，移动操作的次数总是固定的，就等于逆序度。
   
 * 第一，插入排序是原地排序算法吗？
   + 从实现过程可以很明显地看出，插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是 O(1)，也就是说，
   这是一个原地排序算法。
 
 * 第二，插入排序是稳定的排序算法吗？
   + 是
 * 第三，插入排序的时间复杂度是多少？
   + 最好：从尾到头遍历已经有序的数据，O(n)
   + 最坏：数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，
   是O(n^2)
   + 平均
     - 我们在数组中插入一个数据的平均时间复杂度是O(n)，对于插入排序来说，每次插入操作都相当于
     在数组插入一个数据，循环执行n次插入操作所以平均复杂度是O(n^2)
     
 #### 选择排序
  * 也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其
  放到已排序区间的末尾
  * 空间复杂度为O(1)
  * 最好，最坏，平均都是O(n^2)
  * 不稳定排序
  
  
#### 归并排序
 * 使用分治思想，将大问题拆成小问题，小问题解决了大问题最终得到解决
 * 分治算法一般使用递归实现
 * 代码
    ``` 
        // 归并排序算法, A是数组，n表示数组大小
        merge_sort(A, n) {
          merge_sort_c(A, 0, n-1)
        }
        
        // 递归调用函数
        merge_sort_c(A, p, r) {
          // 递归终止条件
          if p >= r  then return
        
          // 取p到r之间的中间位置q
          q = (p+r) / 2
          // 分治递归
          merge_sort_c(A, p, q)
          merge_sort_c(A, q+1, r)
          // 将A[p...q]和A[q+1...r]合并为A[p...r]
          merge(A[p...r], A[p...q], A[q+1...r])
        }
        
        merge(A[p...r], A[p...q], A[q+1...r]) {
          var i := p，j := q+1，k := 0 // 初始化变量i, j, k
          var tmp := new array[0...r-p] // 申请一个大小跟A[p...r]一样的临时数组
          while i<=q AND j<=r do {
            if A[i] <= A[j] {
              tmp[k++] = A[i++] // i++等于i:=i+1
            } else {
              tmp[k++] = A[j++]
            }
          }
          
          // 判断哪个子数组中有剩余的数据
          var start := i，end := q
          if j<=r then start := j, end:=r
          
          // 将剩余的数据拷贝到临时数组tmp
          while start <= end do {
            tmp[k++] = A[start++]
          }
          
          // 将tmp中的数组拷贝回A[p...r]
          for i:=0 to r-p do {
            A[p+i] = tmp[i]
          }
        }
    ```
    
 * 第一，归并排序是稳定的排序算法吗？
   + 归并排序是一个稳定的排序算法
   
 * 第二，归并排序的时间复杂度是多少？
   + 如果我们定义求解问题 a 的时间是 T(a)，
   求解问题 b、c 的时间分别是 T(b) 和 T( c)，
   那我们就可以得到这样的递推关系式：  
     `T(a) = T(b) + T(c) + K`
     
   + 其中K等于将两个子问题b、c的结果合并成问题a的结果所消耗的时间
   
   + 我们假设对 n 个元素进行归并排序需要的时间是 T(n)，那分解成两个子数组排序的时间都是 T(n/2)。
   我们知道，merge() 函数合并两个有序子数组的时间复杂度是 O(n)。
   所以，套用前面的公式，归并排序的时间复杂度的计算公式就是
   ``` 
    T(1) = C； n=1时，只需要常量级的执行时间，所以表示为C。
    T(n) = 2*T(n/2) + n； n>1
    T(n) = 2*T(n/2) + n = 2*(2*T(n/4) + n/2) + n 
         = 4*T(n/4) + 2*n = 4*(2*T(n/8) + n/4) + 2*n 
         = 8*T(n/8) + 3*n = 8*(2*T(n/16) + n/8) + 3*n 
         = 16*T(n/16) + 4*n 
         ...... 
         = 2^k * T(n/2^k) + k * n 
         ......
   ```
   > 通过这样一步一步分解推导，我们可以得到 T(n) = 2^kT(n/2^k)+kn。
   当 T(n/2^k)=T(1) 时，也就是 n/2^k=1，我们得到 k=log2n 。
   我们将 k 值代入上面的公式，得到 T(n)=Cn+nlog2n 。
   如果我们用大 O 标记法来表示的话，T(n) 就等于 O(nlogn)。
   所以归并排序的时间复杂度是 O(nlogn)
 * 第三，归并排序的空间复杂度是多少？
   + 尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。
   在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。
   临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。
   
#### 快速排序
 * 描述
 ``` 
    快排的思想是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，
    我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。
    我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，
    将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，
    前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，
    后面的 q+1 到 r 之间是大于 pivot 的
 ```
 * 代码
 ``` 
    // 快速排序，A是数组，n表示数组的大小
    quick_sort(A, n) {
      quick_sort_c(A, 0, n-1)
    }
    // 快速排序递归函数，p,r为下标
    quick_sort_c(A, p, r) {
      if p >= r then return
      
      q = partition(A, p, r) // 获取分区点
      quick_sort_c(A, p, q-1)
      quick_sort_c(A, q+1, r)
    }  
    
    // 原地排序算法， 空间复杂度为O(1)
    partition(A, p, r) {
      pivot := A[r]
      i := p
      for j := p to r-1 do {
        if A[j] < pivot {
          swap A[i] with A[j]
          i := i+1
        }
      }
      swap A[i] with A[r]
      return i
    }
 ```
 * 快排是一种原地、不稳定的排序算法
 * 最环是O(n^2)  
   ``` 
    我举一个比较极端的例子。如果数组中的数据原来已经是有序的了，
    比如 1，3，5，6，8。如果我们每次选择最后一个元素作为 pivot，那每次分区得到的两个区间都是不均等的。
    我们需要进行大约 n 次分区操作，才能完成快排的整个过程。每次分区我们平均要扫描大约 n/2 个元素，
    这种情况下，快排的时间复杂度就从 O(nlogn) 退化成了 O(n2)。
   ```
   
 * 优化避免O(n^2)复杂度出现
   + 这种 O(n2) 时间复杂度出现的主要原因还是因为我们分区点选的不够合理。
   + 所以最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。
     1. 三数取中法
     2. 随机法
     
   + 还需要注意递归造成栈溢出
     1. 第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归
     2. 通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。


#### 在小规模数据面前，O(n2) 时间复杂度的算法并不一定比 O(nlogn) 的算法执行时间长
 * 时间复杂度代表的是一个增长趋势，如果画成增长曲线图，你会发现 O(n2) 比 O(nlogn) 要陡峭，
 也就是说增长趋势要更猛一些
 * 我们前面讲过，在大 O 复杂度表示法中，我们会省略低阶、系数和常数，
 也就是说，O(nlogn) 在没有省略低阶、系数、常数之前可能是 O(knlogn + c)，
 而且 k 和 c 有可能还是一个比较大的数
 * 例子
   + 假设 k=1000，c=200，当我们对小规模数据（比如 n=100）排序时，n2的值实际上比 knlogn+c 还要小
   ``` 
    knlogn+c = 1000 * 100 * log100 + 200 远大于10000
    n^2 = 100*100 = 10000
   ```
   
 * 所以，对于小规模数据的排序，O(n2) 的排序算法并不一定比 O(nlogn) 排序算法执行的时间长。
   + 对于小数据量的排序，我们选择比较简单、不需要递归的插入排序算法。
